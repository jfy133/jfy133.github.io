[{"authors":null,"categories":null,"content":"üõ† Note: this is a new website, and is still in the process of being transferred! üõ†\nI am a biomolecular archaeologist and bioinformatician. I currently work between the Department of Palaeobiotechnology at the Leibniz Institute for Natural Product Research and Infection Biology Hans Kn√∂ll Institute and Max Planck Institute for Evolutionary Anthropology, while finishing up my my Ph.D. on ancient oral microbiomes .\nI originally trained as an Archaeologist at the University of York, where I specialised in palaeoproteomics. After which I moved to the Universit√§t T√ºbingen to study for an M.Sc. in Archaeological Sciences, specialising in palaeogenetics. During my time in T√ºbingen I also worked as a technician for a stable isotope lab. I worked for a short period for the Institut f√ºr Vor- und Fr√ºhgeschichtliche Arch√§ologie and Provinzialr√∂mische Arch√§ologie at LMU M√ºnchen, developing strategies for authenticating ancient dietary DNA.\nMy current area of research is centred on the ancient DNA content of fossilised dental plaque, also known as dental calculus. My sample set includes individuals spanning from the Palaeolithic to modern day. I am primarily exploring how we can analyse and authenticate the complex genetic make-up of this material through shotgun metagenomics.\nI am involved in the leading and developing of the open-source nexflow pipeline nf-core/eager (v2), which is intended to be a complete re-write and extension of the NGS processing pipeline for ancient DNA data EAGER (v1), to reach modern computational and palaeogenetic standards. I am developing and contributing to multiple open-source software focusing on ancient metagenomics (which can be seen on my github).\nI also established an international community of researchers in ancient metagenomics, and ran the associated SPAAM2 round-table workshop, and I am also a core-team member of the nf-core initiative for best-practise Nextflow bioinformatic pipelines.\nPreviously, I have worked on Late Pleistocene woolly mammoth mitochondrial genomes, as well as testing collagen \u0026lsquo;fingerprinting\u0026rsquo; methods (ZooMS) on burnt skeletal remains.\n  See my resum√©.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"üõ† Note: this is a new website, and is still in the process of being transferred! üõ†\nI am a biomolecular archaeologist and bioinformatician. I currently work between the Department of Palaeobiotechnology at the Leibniz Institute for Natural Product Research and Infection Biology Hans Kn√∂ll Institute and Max Planck Institute for Evolutionary Anthropology, while finishing up my my Ph.","tags":null,"title":"James A. Fellows Yates","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://jfy133.github.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Fellows Yates, James A","Velsko, Irina M","Aron, Franziska","Posth, Cosimo","Hofman, Courtney A","Austin, Rita M","Parker, Cody E","Mann, Allison E","N√§gele, Kathrin","Arthur, Kathryn Weedman","Arthur, John W","Bauer, Catherine C","Crevecoeur, Isabelle","Cupillard, Christophe","Curtis, Matthew C","Dal√©n, Love","Bonilla, Marta D√≠az-Zorita","Carlos D√≠ez Fern√°ndez-Lomana, J","Drucker, Doroth√©e G","Escriv√°, Elena Escribano","Francken, Michael","Gibbon, Victoria E","Gonz√°lez Morales, Manuel R","Mateu, Ana Grande","Harvati, Katerina","Henry, Amanda G","Humphrey, Louise","Men√©ndez, Mario","Mihailoviƒá, Du≈°an","Peresani, Marco","Moroder, Sof√≠a Rodr√≠guez","Roksandic, Mirjana","Rougier, H√©l√®ne","S√°zelov√°, Sandra","Stock, Jay T","Straus, Lawrence Guy","Svoboda, Ji≈ô√≠","Te√ümann, Barbara","Walker, Michael J","Power, Robert C","Lewis, Cecil M","Sankaranarayanan, Krithivasan","Guschanski, Katerina","Wrangham, Richard W","Dewhirst, Floyd E","Salazar-Garc√≠a, Domingo C","Krause, Johannes","Herbig, Alexander","Warinner, Christina"],"categories":null,"content":"Open access publication.\n","date":1621296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621296000,"objectID":"3c216d52777541cc8960019690b7d3d7","permalink":"https://jfy133.github.com/publication/2021-05-10-the-evolution-and-changing-ecology-of-the-african-hominid-oral-microbiome/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2021-05-10-the-evolution-and-changing-ecology-of-the-african-hominid-oral-microbiome/","section":"publication","summary":"We analyzed 124 dental biofilm metagenomes from humans, including Neanderthals and Late Pleistocene to present-day modern humans, chimpanzees, and gorillas, as well as New World howler monkeys for comparison.","tags":["ancient dna","evolution","microbiome","dental calculus","pleistocene","neanderthal"],"title":"The evolution and changing ecology of the African hominid oral microbiome","type":"publication"},{"authors":["Fellows Yates, James A","Lamnidis, Thiseas C","Borry, Maxime","Andrades Valtue√±a, Aida","Fagern√§s, Zandra","Clayton, Stephen","Garcia, Maxime U","Neukamm, Judith","Peltzer, Alexander"],"categories":null,"content":"Open access publication.\n","date":1615852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615852800,"objectID":"70b90a6b8f1a240d0d942e2bb53c9d89","permalink":"https://jfy133.github.com/publication/2021-03-16-reproducible-portable-efficient-ancient-genome-reconstruction/","publishdate":"2021-03-16T00:00:00Z","relpermalink":"/publication/2021-03-16-reproducible-portable-efficient-ancient-genome-reconstruction/","section":"publication","summary":"We present an advanced, and entirely redesigned and extended version of the EAGER pipeline for the analysis of ancient genomic data.","tags":["ancient dna","genomics","metagenomics","bioinformatics","pipeline","nextflow","nf-core"],"title":"Reproducible, portable, and efficient ancient genome reconstruction with nf-core/eager","type":"publication"},{"authors":["Fellows Yates, James A","Andrades Valtue√±a, Aida","V√•gene, √Öshild J","Cribdon, Becky","Velsko, Irina M","Borry, Maxime","Bravo-Lopez, Miriam J","Fernandez-Guerra, Antonio","Green, Eleanor J","Ramachandran, Shreya L","Heintzman, Peter D","Spyrou, Maria A","H√ºbner, Alexander","Gancz, Abigail S","Hider, Jessica","Allshouse, Aurora F","Zaro, Valentina","Warinner, Christina"],"categories":null,"content":"Open access publication.\n","date":1611619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611619200,"objectID":"113ed811be83b980527a8e412780a950","permalink":"https://jfy133.github.com/publication/2021-01-26-community-curated-and-standardised-metadata-of-published-ancient-metagenomic-samples/","publishdate":"2021-01-26T00:00:00Z","relpermalink":"/publication/2021-01-26-community-curated-and-standardised-metadata-of-published-ancient-metagenomic-samples/","section":"publication","summary":"AncientMetagenomeDir (archived at https://doi.org/10.5281/zenodo.3980833) is a collection of annotated metagenomic sample lists derived from published studies that provide basic, standardised metadata and accession numbers to allow rapid data retrieval from online repositories.","tags":["ancient dna","archaeogenetics","palaeogenomics","metagenomics","metagenomes","bioinformatics","data","microbiome","genomics","metadata"],"title":"Community-curated and standardised metadata of published ancient metagenomic samples with AncientMetagenomeDir","type":"publication"},{"authors":["Mann, Allison E","Fellows Yates, James A","Fagern√§s, Zandra","Austin, Rita M","Nelson, Elizabeth A","Hofman, Courtney A"],"categories":null,"content":"Open access publication.\n","date":1605744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605744000,"objectID":"e1d59cc6375f2e227bef74494de2f9d1","permalink":"https://jfy133.github.com/publication/2020-11-24-do-i-have-something-in-my-teeth/","publishdate":"2020-11-19T00:00:00Z","relpermalink":"/publication/2020-11-24-do-i-have-something-in-my-teeth/","section":"publication","summary":"We demonstrate the challenges associated with accurate taxonomic identification and authentication of dietary taxa in ancient DNA data using both synthetic and ancient dental calculus datasets","tags":["ancient dna","dental calculus","dietary dna","diet","archaeology","authentication"],"title":"Do I have something in my teeth? The trouble with genetic analyses of diet from archaeological dental calculus","type":"publication"},{"authors":["Fellows Yates, James A","Valtue√±a, Aida Andrades","V√•gene, Ashild J","Cribdon, Becky","Velsko, Irina M","Borry, Maxime","Bravo-L√≥pez, Miriam J","Fernandez-Guerra, Antonio","Green, Eleanor J","Ramachandran, Shreya L","Heintzman, Peter D","Spyrou, Maria A","H√ºbner, Alexander","Gancz, Abigail S","Hider, Jessica","Allshouse, Aurora F","Warinner, Christina"],"categories":null,"content":"Open access publication.\n","date":1599091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599091200,"objectID":"5a0868afad272b1b4932c43936e905b6","permalink":"https://jfy133.github.com/publication/2020-09-03-community-curated-and-standardised-metadata-of-published-ancient-metagenomic-samples/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/publication/2020-09-03-community-curated-and-standardised-metadata-of-published-ancient-metagenomic-samples/","section":"publication","summary":"AncientMetagenomeDir is a collection of indices of published genetic data deriving from ancient microbial samples that provides basic, standardised metadata and accession numbers to allow rapid data retrieval from online repositories.","tags":["ancient dna","archaeogenetics","palaeogenomics","metagenomics","metagenomes","bioinformatics","data","microbiome","genomics","metadata"],"title":"Community-curated and standardised metadata of published ancient metagenomic samples with AncientMetagenomeDir","type":"publication"},{"authors":["Fellows Yates, J. A.,","Lamnidis, T. C.,","Borry, M.,","Andrades Valtue√±a, A.,","Fagern√§s, Z.,","Clayton, S.,","Garcia, M. U.,","Neukamm, J.,","Peltzer, A."],"categories":null,"content":"Open access publication.\n","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591920000,"objectID":"e4c32a7b8f720526a78e7da43768dfd0","permalink":"https://jfy133.github.com/publication/2020-06-12-reproducible-portable-efficient-ancient-genome-reconstruction/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/publication/2020-06-12-reproducible-portable-efficient-ancient-genome-reconstruction/","section":"publication","summary":"We present nf-core/eager, an advanced and entirely redesigned pipeline for the analysis of ancient genomic data","tags":["ancient dna","genomics","metagenomics","bioinformatics","pipeline","nextflow","nf-core"],"title":"Reproducible, portable, and efficient ancient genome reconstruction with nf-core/eager","type":"publication"},{"authors":null,"categories":null,"content":"It was bothering me that nowhere on the NCBI website are all possible taxonomic \u0026lsquo;ranks\u0026rsquo; actually described.\nI eventually decided to go back to basics and literally download the raw data the NCBI taxonomy website is based on - the infamous taxonomy.dmp, find the column that gives a rank for every single tax. ID, and collapse to all unique values.\nTo do this I downloaded and extracted the taxonomy dump as follows:\nwget ftp://ftp.ncbi.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.zip unzip new_taxdump.zip  Then after hunting through all the files, the one I wanted was nodes.dmp\nThe rank is recorded in the third column,\n$ head nodes.dmp 1 | 1 | no rank | | 8 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | | || 0 | 0 | 0 | 2 | 131567 | superkingdom | | 0 | 0 | 11 | 0 | 0 | 0 | 0 | 0 | | || 0 | 0 | 1 | 6 | 335928 | genus | | 0 | 1 | 11 | 1 | 0 | 1 | 0 | 0 | | || 0 | 0 | 1 | 7 | 6 | species | AC | 0 | 1 | 11 | 1 | 0 | 1 | 1 | 0 | | || 1 | 0 | 1 | 9 | 32199 | species | BA | 0 | 1 | 11 | 1 | 0 | 1 | 1 | 0 | | || 1 | 0 | 1 | 10 | 1706371 | genus | | 0 | 1 | 11 | 1 | 0 | 1 | 0 | 0 | | || 0 | 0 | 1 | 11 | 1707 | species | CG | 0 | 1 | 11 | 1 | 0 | 1 | 1 | 0 | effective current name; | | | 1 | 0 | 1 | 13 | 203488 | genus | | 0 | 1 | 11 | 1 | 0 | 1 | 0 | 0 | | || 0 | 0 | 1 | 14 | 13 | species | DT | 0 | 1 | 11 | 1 | 0 | 1 | 1 | 0 | | || 1 | 0 | 1 | 16 | 32011 | genus | | 0 | 1 | 11 | 1 | 0 | 1 | 0 | 0 | | || 0 | 0 | 1 |  So to extract the column using and collapse to single values, run the following bash-fu\ncat nodes.dmp | cut -d '|' -f 3 | sort | uniq  You get the following result\nbiotype clade class cohort family forma forma specialis genotype genus infraclass infraorder isolate kingdom morph no rank order parvorder pathogroup phylum section series serogroup serotype species species group species subgroup strain subclass subcohort subfamily subgenus subkingdom suborder subphylum subsection subspecies subtribe subvariety superclass superfamily superkingdom superorder superphylum tribe varietas  Note that this doesn\u0026rsquo;t actually give you the hierarchy of all the wierd and wonderful \u0026lsquo;custom\u0026rsquo; groups taxonomists have come up with. However I found by googling \u0026lsquo;NCBI taxonomy \u0026lt;random_rank\u0026gt;\u0026rsquo; I could find enough examples that told me approximately where they fell compared to the standard ranks (even if they are technically analogous e.g. strain vs varietas)\nThe ones I did find:\n parvorder - comes after order section - comes after genus \u0026lsquo;strain\u0026rsquo;, \u0026lsquo;morph\u0026rsquo;, \u0026lsquo;forma specialis\u0026rsquo; - comes after species  ","date":1584403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584403200,"objectID":"cf3f0c5ace6e6a4dafa27c3e19c2d1f0","permalink":"https://jfy133.github.com/post/2020-07-23-all-ncbi-taxonomy-ranks/","publishdate":"2020-03-17T00:00:00Z","relpermalink":"/post/2020-07-23-all-ncbi-taxonomy-ranks/","section":"post","summary":"How to to get all possible ranks in the NCBI taxonomy","tags":["bioinformatics","ncbi","taxonomy"],"title":"All Possible NCBI Taxonomy Ranks","type":"post"},{"authors":null,"categories":null,"content":"I have written a tutorial in the form of a slideshow, which step-by-step introduces a new user to nf-core/eager\nnf-core/eager is a reproducible and portable pipeline for pre-processing and performing standard ancient DNA screening analysis.\n Or in full screen here: Intro to nf-core/eager\n","date":1584403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584403200,"objectID":"b05fe1b96f70410ccd521954a1cf401d","permalink":"https://jfy133.github.com/post/2020-03-17-nfcore-eager-tutorial/","publishdate":"2020-03-17T00:00:00Z","relpermalink":"/post/2020-03-17-nfcore-eager-tutorial/","section":"post","summary":"Gentle introduction on how to use nf-core eager","tags":["bioinformatics","tutorial","simple","nf-core/eager","eager2","aDNA","palaeogenetics","archaeogenetics"],"title":"Gentle introduction to nf-core/eager","type":"post"},{"authors":["Swift, Jillian A","Bunce, Michael","Dortch, Joe","Douglass, Kristina","Faith, J Tyler","Fellows Yates, James A","Field, Judith","Haberle, Simon G","Jacob, Eileen","Johnson, Chris N","Lindsey, Emily","Lorenzen, Eline D","Louys, Julien","Miller, Gifford","Mychajliw, Alexis M","Slon, Viviane","Villavicencio, Natalia A","Waters, Michael R","Welker, Frido","Wood, Rachel","Petraglia, Michael","Boivin, Nicole","Roberts, Patrick"],"categories":null,"content":"Open access publication.\n","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"20fb12a1237fc1ccc2d9783d3e1d171e","permalink":"https://jfy133.github.com/publication/2019-10-02-micro-methods-megafauna/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/publication/2019-10-02-micro-methods-megafauna/","section":"publication","summary":"In the present article, we highlight how developments in five such methodologies (radiocarbon approaches, stable isotope analysis, ancient DNA, ancient proteomics, microscopy) have helped drive detailed analysis of specific megafaunal species, their particular ecological settings, and responses to new competitors or predators, climate change, and other external phenomena.","tags":["mammoth","megafauna","pleistocene","ancient dna","palaeogenetics","archaeological science","review"],"title":"Micro Methods for Megafauna: Novel Approaches to Late Quaternary Extinctions and Their Contributions to Faunal Conservation in the Anthropocene","type":"publication"},{"authors":["Velsko, Irina M","Fellows Yates, James A","Aron, Franziska","Hagan, Richard W","Frantz, Laurent A F","Loe, Louise","Martinez, Juan Bautista Rodriguez","Chaves, Eros","Gosden, Chris","Larson, Greger","Warinner, Christina"],"categories":null,"content":"Open access publication.\n","date":1562371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562371200,"objectID":"b357096ce74f17b94744935c335b4367","permalink":"https://jfy133.github.com/publication/2019-07-06-microbial-differences-plaque-calculus/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2019-07-06-microbial-differences-plaque-calculus/","section":"publication","summary":"Here, we compare the microbial profiles of modern dental plaque, modern dental calculus, and historic dental calculus to establish expected differences between these substrates.","tags":["ancient dna","archaeogenetics","microbiome","metagenomics","dental calculus"],"title":"Microbial differences between dental plaque and historic dental calculus are related to oral biofilm maturation stage","type":"publication"},{"authors":null,"categories":null,"content":"I recently was using the R package pvclust to test the \u0026lsquo;robusticity\u0026rsquo; of clusters in a microbiome-related clustering analysis. While pvclust provides it\u0026rsquo;s own plots via plot() on a pvclust object, this plots the dendrogram in base R. For readability and customisability reasons I prefer using the packages ggplot2 and ggtree for making my figures. However, I was having a hard time to extract the node uncertainty values from the pvclust object and integrate them into a generic R phylo object for plotting the dendrogram in ggtree.\nFortunately, a bit of googling (a couple of days\u0026hellip;) showed me someone else had already solved the problem of transferring additional hclust information into a phylo object but in a different context. The fastbap package has the function as.phylo.hclust.node.attributes()which essentially does what I needed to do - i.e. when calculating the node numbers from each merge event, also store with the same node number the corresponding attribute, or in this case,pvclust` AU value.\nI then modified this function slightly to make it more consistent with how pvclust will display the values in the base R plot (rounding and converting to a \u0026lsquo;percentage\u0026rsquo;). Note that this outputs in the phylo object the metadata node.label, not as node.attributes as in the original fastbaps function.\nSo in summary:\n## 1. Make pvclust object e.g. hclust_boot \u0026lt;- pvclust::pvclust(otu_matrix, method.hclust = selected_method, method.dist = \u0026quot;euclidean\u0026quot;, nboot = 1000, parallel = T) ## 2. Set modified fastbaps function as.phylo.pvclust.node.attributes \u0026lt;- function(x, attribute) { N \u0026lt;- dim(x$merge)[1] edge \u0026lt;- matrix(0L, 2*N, 2) edge.length \u0026lt;- numeric(2*N) ## `node' gives the number of the node for the i-th row of x$merge node \u0026lt;- integer(N) node[N] \u0026lt;- N + 2L node.attributes \u0026lt;- rep(NA, N) cur.nod \u0026lt;- N + 3L j \u0026lt;- 1L for (i in N:1) { edge[j:(j + 1), 1] \u0026lt;- node[i] for (l in 1:2) { k \u0026lt;- j + l - 1L y \u0026lt;- x$merge[i, l] if (y \u0026gt; 0) { edge[k, 2] \u0026lt;- node[y] \u0026lt;- cur.nod cur.nod \u0026lt;- cur.nod + 1L edge.length[k] \u0026lt;- x$height[i] - x$height[y] node.attributes[edge[k, 1] - (N + 1)] \u0026lt;- attribute[i] } else { edge[k, 2] \u0026lt;- -y edge.length[k] \u0026lt;- x$height[i] node.attributes[edge[k, 1] - (N + 1)] \u0026lt;- attribute[i] } } j \u0026lt;- j + 2L } if (is.null(x$labels)) x$labels \u0026lt;- as.character(1:(N + 1)) ## MODIFICATION: clean up node.attributes so they are in same format in ## pvclust plots node.attributes \u0026lt;- as.character(round(node.attributes * 100, 0)) node.attributes[1] \u0026lt;- NA obj \u0026lt;- list(edge = edge, edge.length = edge.length / 2, tip.label = x$labels, Nnode = N, node.label = node.attributes) class(obj) \u0026lt;- \u0026quot;phylo\u0026quot; stats::reorder(obj) } ## 3. Use the modified fastbaps function by accessing the hclust object in first ## position, and the corresponding au values from the edges list entry. hclust_boot_phylo \u0026lt;- as.phylo.pvclust.node.attributes(hclust_boot$hclust, hclust_boot$edges$au)  To display the values on the tree with ggtree you can then run\nggtree(hclust_boot_phylo aes(x, y)) + geom_text2(aes(subset = !isTip, label = label))  as described in the ggtree FAQ under the section \u0026ldquo;bootstrap values from newick format\u0026rdquo;.\n","date":1560816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560816000,"objectID":"b1b0ef8faa6005f2e414630793717abf","permalink":"https://jfy133.github.com/post/2019-06-18-pvclust-nodevalues-in-ggtree/","publishdate":"2019-06-18T00:00:00Z","relpermalink":"/post/2019-06-18-pvclust-nodevalues-in-ggtree/","section":"post","summary":"How to display bootstrap values from pvclust on a phylogenetic tree made in ggtree","tags":["bioinformatics","ggtree","pvclust","bootstrap_values"],"title":"pvclust Node Values In ggtree","type":"post"},{"authors":null,"categories":null,"content":"Many people in the human population-genetics groups in my department at MPI-SHH use a propetiary Mac specific program to make their figures of PCAs (principle component analysis). Some of the members of these groups however do not have Macs and were struggling to recreate some of the plots their collegues were making.\nIn response, I wrote a markdown document describing how you would recreate a PCA from a recent paper from my friend Thiseas Lamnidis but in R.\nThis tutorial is released under the open CC-BY-SA 4 license and can be viewed by anyone at the following link: https://github.com/jfy133/Tidy_PopGen_PCA_Plotting.\nI am updating the tutorial as requests come in for different modifications, so please check back regularly or leave an issue on the github repository with requests.\n   ","date":1556841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556841600,"objectID":"11e0828e24d526aced490f27b7c5d9b5","permalink":"https://jfy133.github.com/post/2019-05-03-tidy-popgen-pca-plotting-in-r/","publishdate":"2019-05-03T00:00:00Z","relpermalink":"/post/2019-05-03-tidy-popgen-pca-plotting-in-r/","section":"post","summary":"How to plot PCAs for (ancient) population genetics using R and the tidyverse","tags":["r","tidyverse","pop-gen","tutorial"],"title":"'Tidy' Pop-Gen PCA plotting in R","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://jfy133.github.com/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Mann, Allison E","Sabin, Susanna","Ziesemer, Kirsten","V√•gene, √Öshild J","Schroeder, Hannes","Ozga, Andrew T","Sankaranarayanan, Krithivasan","Hofman, Courtney A","Fellows Yates, James A","Salazar-Garc√≠a, Domingo C","Frohlich, Bruno","Aldenderfer, Mark","Hoogland, Menno","Read, Christopher","Milner, George R","Stone, Anne C","Lewis Jr, Cecil M","Krause, Johannes","Hofman, Corinne","Bos, Kirsten I","Warinner, Christina"],"categories":null,"content":"Open access publication.\n","date":1530230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530230400,"objectID":"c41957abb394919b6f7349a5c8158619","permalink":"https://jfy133.github.com/publication/2018-06-29-differential-preservation-endogenous/","publishdate":"2018-06-29T00:00:00Z","relpermalink":"/publication/2018-06-29-differential-preservation-endogenous/","section":"publication","summary":"In this study, shotgun-sequenced data from paired dental calculus and dentin samples from 48 globally distributed individuals are compared using a metagenomic approach.","tags":["ancient dna","dental calculus","metagenomics","microbiome","archaeogenetics"],"title":"Differential preservation of endogenous human and microbial DNA in dental calculus and dentin","type":"publication"},{"authors":["Fellows Yates, James A","Drucker, Doroth√©e G","Reiter, Ella","Heumos, Simon","Welker, Frido","M√ºnzel, Susanne C","Wojtal, Piotr","L√°zniƒçkov√°-Galetov√°, Martina","Conard, Nicholas J","Herbig, Alexander","Bocherens, Herv√©","Krause, Johannes"],"categories":null,"content":"Open access publication.\n","date":1513555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513555200,"objectID":"f01f7d376fff183655e0a15ec7f5374a","permalink":"https://jfy133.github.com/publication/2017-12-18-central-european-woolly-mammoth/","publishdate":"2017-12-18T00:00:00Z","relpermalink":"/publication/2017-12-18-central-european-woolly-mammoth/","section":"publication","summary":"We use a multi-method approach utilising proteomic, stable isotope and genetic techniques to identify and generate twenty woolly mammoth mitochondrial genomes, and associated dietary stable isotopic data, from highly fragmentary Late Pleistocene material from central Europe.","tags":["mammoth","megafauna","pleistocene","ancient dna","palaeogenetics","population genetics"],"title":"Central European Woolly Mammoth Population Dynamics: Insights from Late Pleistocene Mitochondrial Genomes","type":"publication"},{"authors":null,"categories":null,"content":"I am new to Git and Github, and so I am still very much learning on the fly. Today I noticed the original repository for the theme of this website had added updates, so I thought to apply them to my own repository.\nThis wasn\u0026rsquo;t as straightforward as it seemed, so here I have written down my instructions how to apply the fixes in the future.\nThe instructions are essentially a merging of what I read on these three pages:\n https://help.github.com/articles/fork-a-repo/ https://help.github.com/articles/syncing-a-fork/ http://genomewiki.ucsc.edu/index.php/Resolving_merge_conflicts_in_Git  I assume this is applicable for all Git related repo manipulations, but in this tutorial I am focusing on updating a Github pages theme.\nInstructions  Change into my local repository on my laptop, and initialise  cd ~/\u0026lt;path\u0026gt;/\u0026lt;to\u0026gt;/\u0026lt;local_repo/ git init  Check the remote information, and if no upstream branches present - add them. In this case I\u0026rsquo;m using the repo I used for my website  git remote -v git remote add upstream https://github.com/academicpages/academicpages.github.io.git  Find the changes in the upstream branch  git fetch upstream  Now check out of branch (not sure if this was needed, but didn\u0026rsquo;t do any harm)  git checkout master  Now we attempt to merge the changes. Git will take anything in the upstream branch, and if no change has been made on the my personal repo in the past, will make the change. Otherwise, merge conflict errors will be printed to screen.  git merge upstream/master  Take a look at which files have the merge conflicts, and inside each file look at the sections with \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, ===== or \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; and manually remove the changes (normally the upstream, or one below the =====) that you don\u0026rsquo;t want changed. Remove the symbols above as well, save the the file. Add the file to the commit to indicate you\u0026rsquo;ve \u0026lsquo;fixed\u0026rsquo; the merge conflict, for example:  git add _config.yml  Once you\u0026rsquo;ve fixed all the merge conflicts, you can do a normal git commit and push.  git commit -m \u0026quot;Merged with \u0026lt;upstream_repo\u0026gt;\u0026quot;  And with that your website theme should be updated.\n","date":1507420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507420800,"objectID":"c87ff011a8dac90fd66fc4abaf9e5586","permalink":"https://jfy133.github.com/post/2017-10-08-updating-github-pages-theme/","publishdate":"2017-10-08T00:00:00Z","relpermalink":"/post/2017-10-08-updating-github-pages-theme/","section":"post","summary":"How to fetch and merge upstream changes of a github pages theme","tags":["website","github","jekyll","theme","tutorial"],"title":"Updating a Github Pages Theme Through a Repo Merge","type":"post"},{"authors":null,"categories":null,"content":"As I came to the end of my M.Sc. and writing the corresponding journal article, one thing I was aware of was that all previous papers on woolly mammoth mitchondrial genomes to NCBI\u0026rsquo;s GenBank database. To continue with this established \u0026lsquo;tradition\u0026rsquo;, I decided to investigate how to do this. Worringly, most people I spoke to didn\u0026rsquo;t have very positive views on this procdure, saying that it was complicated, error prone and badly documented and that it wasn\u0026rsquo;t worth my time. In fact, with a bit of help from the authors of some of the previous papers and with NCBI itself, the overall task ended up being easier than expected (admittedly after a considerable bit of trial and error).\nHere, I describe the eventual steps that I did to (successfully!) annotate a set of mtGenomes and make a submission to GenBank. However, note that these instructions are only valid for this use-case, and would not be necessarily valid for other situations.\nIn this case, we assume that you have multiple sequences of a species that already has an annotated reference sequence on GenBank. I use here the \u0026lsquo;Krause\u0026rsquo; reference (Accession: NC_007596.2) and my reconstructed mtGenomes.\nPreparation  Download the program Sequin from here (If running Ubuntu 16.04 might have to install libxp6 from the PPA here). Download the reference sequence from Genbank in FASTA format and the FeatureTable format. Using a multisequence aligner tool like MEGA or Geneious, align your sequences to the reference, and export the file as a FASTA file (make sure to export gaps as Ns, and not \u0026lsquo;-\u0026rsquo; as in the documentation, and keep the reference sequence!). To save time later, you now want to change the FASTA headers for each sequnce to the NCBI format, adding as much information as you can using the \u0026lsquo;modifiers\u0026rsquo; listed here. An example of one of my headers is as so:  \u0026gt;JK2760 [organism=Mammuthus primigenius] [country=Germany] [isolate=JK2760] Mammuthus primigenius isolate JK2760 mitochondrion, partial genome  For the reference sequence you should also add the tag [acc=NC_007596.2].\nUsing Sequin Next we can start Sequin, select \u0026lsquo;NCBI GenBank\u0026rsquo; and \u0026lsquo;Start new submission\u0026rsquo;.    Set the release date of the data (for example if you want to release on the same day as your paper is published - note you can update this later) and add a tentative title for the study.    Set you name, phone and email (fax can be skipped).    Enter the names of the authors of the study.    Enter the submitting institution address (fax can be skipped).    Select the \u0026lsquo;use normal submission dialog\u0026rsquo; option.    Select \u0026lsquo;Population Study\u0026rsquo;, \u0026lsquo;Alignment\u0026rsquo; and \u0026lsquo;Original submission\u0026rsquo;.    Now you can import your FASTA alignment through the \u0026lsquo;Import Alignment\u0026rsquo; button and select the following options:   Trim Ns at the end of sequences: yes. Specify molecule: \u0026lsquo;Genomic DNA\u0026rsquo; (apply to all). Specify topology: \u0026lsquo;linear\u0026rsquo; (apply to all).       Select \u0026lsquo;Illumina\u0026rsquo;, \u0026lsquo;assembled sequences\u0026rsquo; and input your assembly program (in my case it is bwa and version \u0026lsquo;0.7\u0026rsquo;).    Next you can add various information like organisms, locations (e.g. here I selected mitochondrion) and genetic codes (to apply to all you can select the header). You can keep the genetic code as \u0026lsquo;standard\u0026rsquo; or change to \u0026lsquo;Vertebrate Mitochondrial\u0026rsquo;. Some of this will have already been imported based on your FASTA headers.      You can skip the protein step. You can also skip annotation (select \u0026lsquo;none\u0026rsquo;) and \u0026lsquo;Continue to record viewer\u0026rsquo;.      First, it is best to annotate any runs of Ns as sequencing gaps (as per advice from the NCBI helpdesk). You can do this by doing the following:   In record viewer Go to Search Validate \u0026gt; Validate. Double click on a \u0026lsquo;run of Ns\u0026rsquo; error.    In the sequence viewer, type in the start position (-1) in the \u0026lsquo;Go to\u0026rsquo; box. Then click and drag until all the Ns are selected.    Then go to Features \u0026gt; Remaining Features \u0026gt; misc_features and under the \u0026lsquo;Properties\u0026rsquo; and then \u0026lsquo;Comment\u0026rsquo; tab you can add \u0026lsquo;sequencing gap, estimated length 119 bp\u0026rsquo;.     Once all of those are done, in the Record Viewer you need to select from the drop down menu the reference sequence (in this case NC_007596.2) and then File \u0026gt; Open the Genbank (flat)file or the feature table. This should automatically load all the annotations of the original sequence, also \u0026lsquo;importing\u0026rsquo; features that in the latest version of Sequin fail due to conflicts (e.g. I could not manually make a /trans_exep, but when I imported it gives an error but keeps the feature). Finally in the Record Viewer you can go Edit \u0026gt; Feature Propagate. This will copy over all of the annotations on the reference sequnce to your other sequences, but doing the correct DNA to amino acid translation.    You should now do another \u0026lsquo;validate\u0026rsquo; to find any errors. For example a couple of my translated amino acid sequences began with XXXXXX, so the Sequin couldn\u0026rsquo;t find the start codon and thus failed. I just removed these feature entries (and informed NCBI staff). Once you have no failures, you can go in Record Viewer to \u0026lsquo;File \u0026gt; Prepare Submission\u0026rsquo; and send the corresponding file to NCBI genbank as per the instructions. here.  Once done, after a few days you should recieve a message from the NCBI either with corrections to be made or a list of accession numbers, which will go live on the date you selected in Sequin.\nTo update or to get the release date changed you can just email them again at the same address (you don\u0026rsquo;t need to do a resubmission or use sequin).\n","date":1501718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501718400,"objectID":"5cfb1623a6d629aa3b35ebed9dafebbd","permalink":"https://jfy133.github.com/post/2017-08-03-sequin-genbank-submission/","publishdate":"2017-08-03T00:00:00Z","relpermalink":"/post/2017-08-03-sequin-genbank-submission/","section":"post","summary":"How to submit ancient mitochondrial consensus sequences to Genbank with Sequin","tags":["bioinformatics","ncbi","tutorial"],"title":"Sequin Submission to Genbank Tutorial","type":"post"},{"authors":null,"categories":null,"content":"During my M.Sc. thesis I started to use the Bayesian phylogenetic MrBayes on clusters that do not make it feasible to keep open a terminal window. This meant I had to use ‚Äòbatch mode‚Äô, meaning I could only follow the status of the MrBayes run through the log files.\nOne issue I found when using MrBayes is that it is quite slow, so when I found my MCMC trace reached stability very early on in the chain, I wanted to stop the chain early, requiring me to force cancel the run. This meant that the data was not loaded in the program and I could not run the ‚Äòsump‚Äô or ‚Äòsumt‚Äô commands in MrBayes.\nI googled how to do cancel a MrBayes run early and found a couple of links (such as here and here). Although easy to do, neither explanations were particularly explicit in how finish the chain early and continue the analysis.\nThis post will give a quick step by step guide with additional notes on how to cancel a run early and to finish the analyses.\n  Submit your batch script to your cluster\n  Check your log file, and once you are at a stage you wish to stop the run, cancel the run.\n  To the end of every ‚Äò.t‚Äô file, in a text editor or with the command line, append to a new line without an indentation the following:\n     Note: If you want to ‚Äòround off‚Äô your number of steps in your chain, make sure you have the same numbers of entries in both .t and .p files. E.g. if you had already reached stability by 40,000,000 steps but you finished 40,000,125 - in all files delete lines below 40,000,000 and add ‚Äòend;‚Äô in the tree files.\nNow open MrBayes again (typically with mb) and re-load the original nexus file you selected in your batch file.  Note: If you selected a different name for the output of the run in your batch file, you may have to re-name the input nexus file to that of the output files (so it is the same as the .mcmc, .t, .p files etc.)\nNow, as you would normally, run the ‚Äòsump‚Äô and ‚Äòsumt‚Äô commands to summarise your run and generate your consensus trees.  Hopefully this will allow you to get your results much faster rather letting the run to finish (in my case saving around 3 weeks)!\n","date":1495929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495929600,"objectID":"0e3a8d31929378435fb60a0e4827a04f","permalink":"https://jfy133.github.com/post/2017-05-28-cancel-mybayes-early/","publishdate":"2017-05-28T00:00:00Z","relpermalink":"/post/2017-05-28-cancel-mybayes-early/","section":"post","summary":"How to cancel MrBayes run early","tags":["mrbayes","phylogenetics"],"title":"How-to: cancel a MrBayes run early","type":"post"},{"authors":null,"categories":null,"content":"In Archaeology, or other disciplines that looking through deep time, you often want to represent change through time. A simple example of this, is representing the location different archaeological sites through different cultural periods.\nI have had an issue quite a few times during my B.Sc., M.Sc. and now in my P.hD., which is how to quickly make a series of \u0026lsquo;semi\u0026rsquo; good-looking maps, that simply represent the locations of different sites over time.\nMany people use fancy programs like qGIS to include terrain and other details, but often these tools (although powerful) are unwieldy to use and take a long time to get familiar with before producing something you are looking for. Although Google Maps is another alternative - such as through Google Drive\u0026rsquo;s Fusion tables, often I find this still does not look as professional as those you see in academic publications.\nThe programming language I am most familiar with currently is R, and although this also has a learning-curve, it is not too hard to copy and paste code into something like R-Studio and quickly get some output. Furthermore, for scientists, R is one of the best languages to go to for data analysis and manipulating data (as well as getting pretty plots).\nGoogling \u0026ldquo;maps in R\u0026rdquo; show many posts on how to do just that. However when I have tried this multiple times in the past, the many tutorials were either out-of-date, using packages that were even more out of date (one I used a year ago still used a map that had the Soviet Union!) and often these tutorials did not just give you an example of simply placing points on a map!\nThe closet tutorial I found was from here: https://www.r-bloggers.com/world-map-panel-plots-with-ggplot2-2-0-ggalt/, yet this was still doing much more than I actually needed.\nHere, I will document the simplest solution I have found, based on the above, requiring only a table of sites with metadata including \u0026lsquo;lat:lon\u0026rsquo; coordinates (in the form of decimals, as you would get from Google Maps), the base install of R, and the (arguably) best looking and most popular plotting package ggplot2,\nFor this example, I will use the coordinates of the places I have previously studied in and save this as a .tsv (tab separated) file :\n   City Lat Long PeriodYork     York 53.943540 -1.061194 B.Sc.   T√ºbingen 48.518484 9.058082 M.Sc.   Jena 50.903443 50.903443 Ph.D.    I then ran the following R commands (in R v3.2.3):\n##Load library ggplot2 (to install: install.packages(\u0026quot;ggplot2\u0026quot;), and choose your closest server library(ggplot2) ##Set your working directory setwd(\u0026quot;~/Downloads\u0026quot;) ##Load the world map from within ggplot2 and remove antarctica ##(you can leave the removal of a country out, or add more countries with a list) world \u0026lt;- map_data(\u0026quot;world\u0026quot;) world \u0026lt;- world[world$region != \u0026quot;Antarctica\u0026quot;,] ##Load your data dat \u0026lt;- read.csv(\u0026quot;city_coords.tsv\u0026quot;, sep=\u0026quot;\\t\u0026quot;, header=TRUE) ##Here you load your ggplot object into a variable gg \u0026lt;- ggplot() ##Here you format your world map, line colour, object fill, and line size ##and transparency gg \u0026lt;- gg + geom_map(data=world, map=world, aes(x=long, y=lat, map_id=region), color=\u0026quot;white\u0026quot;, fill=\u0026quot;#7f7f7f\u0026quot;, size=0.05, alpha=1/4) ##Here you apply your points you wish to project onto the map, ##in this case automatically coloured by another variable (Period). ##You can define the colours you wish of each period by adding ##+ scale_color_manual(values=c(\u0026quot;#377eb8\u0026quot;, \u0026quot;#984ea3\u0026quot;, \u0026quot;#4daf4a\u0026quot;)) ##after the geom_point close bracket. Each RGB colour represents the ##colour of each entry in the 'Period' column, in alphabetical order. gg \u0026lt;- gg + geom_point(data=dat, aes(x=Long, y=Lat, color=Period), size=1) ##Here you can remove the legend, look into ggplot2's theme() variable ##to remove other things like tick marks etc. gg \u0026lt;- gg + theme(legend.position=\u0026quot;none\u0026quot;) ##Here you can 'crop' your picture to a region you are interested in, ##and apply this in the decimal coordinate system as with your points. ##You will have to play around with this a lot depending on what you ##want to crop out, as how this displayed depends on your plot window size ##(draggable in R) longlimits \u0026lt;- c(-10, 20) latlimits \u0026lt;- c(40, 60) gg \u0026lt;- gg + coord_cartesian(xlim = longlimits, ylim = latlimits) #Open the final image, saying you want a column with each time period on ##each row. To make horizontal you switch the Period with the full stop. gg + facet_grid(Period ~ .) ##Adapted from: ## https://www.r-bloggers.com/world-map-panel-plots-with-ggplot2-2-0-ggalt/  And you will get something like the following output (following some resizing of the window):\n   Once you\u0026rsquo;ve got the image you like, you can then save in a variety of formats by adding the R functions svg(\u0026quot;my_map.svg\u0026quot;, width=5, height=10) or png(\u0026quot;my_map.png\u0026quot;, width=50, height=100) prior the final command and putting dev.off() after the last command. The image should then be saved in your \u0026lsquo;working directory\u0026rsquo; set at the beginning.\nBased on that basic outline, you can look into the ggplot2 for further modifications (point shapes, colouring by certain continuous values etc.)\n","date":1495929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495929600,"objectID":"40524efc780c2c8844adba8e43f37407","permalink":"https://jfy133.github.com/post/2017-05-28-maps-in-r/","publishdate":"2017-05-28T00:00:00Z","relpermalink":"/post/2017-05-28-maps-in-r/","section":"post","summary":"How to make change over time / time transect maps for Archaeological science","tags":["r","how-to","maps"],"title":"How-to: Simple 'change over time' maps in R","type":"post"},{"authors":["Warriner, C","Herbig, A","Mann, A","Fellows Yates, J.A.","Wei√ü, C.L.","Burbano, H.A.","Orlando, L","Krause, J"],"categories":null,"content":"Open access publication.\n","date":1492387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492387200,"objectID":"6c7663dd3318f8d460c6e2517f3e4aae","permalink":"https://jfy133.github.com/publication/2017-04-17-robust-framework-microbial-archaeology/","publishdate":"2017-04-17T00:00:00Z","relpermalink":"/publication/2017-04-17-robust-framework-microbial-archaeology/","section":"publication","summary":"Here, we introduce the fundamental concepts and theoretical framework of the discipline, then discuss applied methodologies for pathogen identification and microbiome characterization from archaeological samples.","tags":["ancient metagenomics","ancient dna","palaeogenomics","microbiomes","review","authentication"],"title":"A Robust Framework for Microbial Archaeology","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://jfy133.github.com/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"AncientMetagenomeDir is a creative-commons licensed community curated resource of lists of all published shotgun-sequenced ancient metagenome or microbial genome-level enriched samples. It is primarily meant to act as a reference guide to help point researchers toward any relevant public data for comparative analysis. It is hoped it will help researchers track growth and development of the field of ancient metagenomics over time.\nI established this project, lead development, and contribute to the ongoing maintenance of the repository.\nThe first release was published in Scientific Data (open access).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c908d2df8b1f6facba6ed95acefead0a","permalink":"https://jfy133.github.com/project/ancientmetagenomedir/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/ancientmetagenomedir/","section":"project","summary":"Community curated repository of ancient metagenomic sample metadata","tags":["ancient DNA","ancient metagenomics","metadata","SPAAM"],"title":"AncientMetagenomeDir","type":"project"},{"authors":null,"categories":null,"content":"nf-core/eager is a scalable and reproducible bioinformatics best-practise processing pipeline for genomic NGS sequencing data, with a focus on ancient DNA (aDNA) data. It is ideal for the (palaeo)genomic analysis of humans, animals, plants, microbes and even microbiomes.\nThe pipeline is built using Nextflow, a workflow tool to run tasks across multiple compute infrastructures in a very portable manner. It comes with docker containers making installation trivial and results highly reproducible. The pipeline pre-processes raw data from FASTQ inputs, or preprocessed BAM inputs. It can align reads and performs extensive general NGS and aDNA specific quality-control on the results. It comes with docker, singularity or conda containers making installation trivial and results highly reproducible.\nI co-lead development, and the current maintainer of the pipeline.\nThe pipeline was published in PeerJ (open access).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5ab36e803d1e9ce382b6b6e96755fcc1","permalink":"https://jfy133.github.com/project/nf-core_eager/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/nf-core_eager/","section":"project","summary":"nf-core/eager is a scalable and reproducible bioinformatics best-practise processing pipeline for genomic NGS sequencing data, with a focus on ancient DNA (aDNA) data, written in Nextflow.","tags":["ancient DNA","ancient metagenomics","Nextflow","nf-core","eager","genomics","metagenomics","pipeline","bioinformatics"],"title":"nf-core/eager","type":"project"},{"authors":null,"categories":null,"content":"The SPAAM community is a group of researchers focusing on ancient metagenomics.\nWe aim to regularly meet to share knowledge on solutions to common challenges and obstacles that the field faces, with cycling organising committees. We also collectively run projects for the benefit of the whole community.\nI established the community, and co-organised the SPAAM2 meeting in 2020. I continue to act as \u0026lsquo;caretaker\u0026rsquo; of the community and help establish new projects and collaborations between researchers.\nWe have an open slack channel that can be joined via the link on the website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"56d1eddc35c4f43619550f9968235e7f","permalink":"https://jfy133.github.com/project/spaam/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/spaam/","section":"project","summary":"The SPAAM community (Standards Precautions and Advances in Ancient Metagenomics) of ancient metagenomics researchers","tags":["ancient DNA","ancient metagenomics","metagenomics","community","meetings","workshops","discussion","early career researchers"],"title":"SPAAM Community","type":"project"}]